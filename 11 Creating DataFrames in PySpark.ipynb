{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851c1762",
   "metadata": {},
   "source": [
    "## Introduction to Creating DataFrames in PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6054a6a",
   "metadata": {},
   "source": [
    "### Links and Resources\n",
    "- [createDataFrame](https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.createDataFrame.html) \n",
    "- [Spark Data Types](https://spark.apache.org/docs/3.5.3/sql-ref-datatypes.html)\n",
    "- [Data Types Class](https://spark.apache.org/docs/3.5.3/api/python/reference/pyspark.sql/data_types.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f8d1e",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to create DataFrames from Python data structures, specify schemas, and explore various methods to view and manipulate the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple data structure\n",
    "data = [['John', 21]]\n",
    "# Check the type of the data structure\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92256216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the data structure\n",
    "df = spark.createDataFrame(data)\n",
    "# Display the contents of the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the type of the DataFrame\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8178b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a data structure with multiple records\n",
    "data = [('John', 21), ('Amy', 25), ('Anita', 41), ('Rohan', 25), ('Maria', 37)]\n",
    "# Create a DataFrame from the data structure\n",
    "df = spark.createDataFrame(data)\n",
    "# Display the contents of the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16f32f",
   "metadata": {},
   "source": [
    "### Adding a Schema with Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e726594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "column_names = ['name', 'age']\n",
    "# Create a DataFrame with the defined column names\n",
    "df = spark.createDataFrame(data, column_names)\n",
    "# Display the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bae484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema using SQL-like syntax\n",
    "schema = 'name string, age int'\n",
    "# Create a DataFrame using the defined schema\n",
    "df = spark.createDataFrame(data, schema)\n",
    "# Display the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6174f0db",
   "metadata": {},
   "source": [
    "### Exploring Spark Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e89b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySpark data types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Define a schema using StructType and StructField\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Create a DataFrame with the custom schema\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "# Display the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5401dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the schema of the DataFrame\n",
    "print(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a754a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data types of the DataFrame columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cef003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the schema using the printSchema() method\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics for the DataFrame\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7b413",
   "metadata": {},
   "source": [
    "### Creating a DataFrame from a List of Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f442a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data as a list of dictionaries\n",
    "data = [\n",
    "    {'name': 'John', 'age': 21},\n",
    "    {'name': 'Amy', 'age': 25},\n",
    "    {'name': 'Anita', 'age': 41},\n",
    "    {'name': 'Rohan', 'age': 25},\n",
    "    {'name': 'Maria', 'age': 37}\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = spark.createDataFrame(data)\n",
    "# Display the contents of the DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b11400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), False)\n",
    "])\n",
    "\n",
    "# Create a DataFrame using the defined schema\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "# Display the DataFrame\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
